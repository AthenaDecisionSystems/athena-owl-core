default_prompt:
  name:  Default prompt
  locales:
  - locale: en
    text: "Answer the user's question based on the conversation history: {chat_history} \n\n question: {input}. If you do not know the answer, respond that you do not know."
  - locale: fr
    text: "Repond aux questions de l'utilisateur en prenant en compte le historique de la conversation: \n\n{chat_history}  \n\n et la question: {input}"
  - locale: es
    text: "Responda las preguntas del usuario seg√∫n el historial de conversaciones  {chat_history} \n\n question: {input}"

openai_functions_prompt:
  name: OpenAI tool calling prompt
  locales:
  - locale: en
    text: |
      you are a helpful assistant using tools when needed by using {agent_scratchpad}
      keeping conversation history: {chat_history}
      to answer the question: {input}

graph_prompt:
  name: A prompt for tool and graph
  locales:
  - locale: en
    text: |
      you are a helpful assistant using tools by using {agent_scratchpad}. Do not invente the answer, try to use tool when appropriate.


mistral_rag_prompt:
    name: Mistral Bank Query Classification
    locales:
    - locale: en
      text: |
        "Answer the following question based only on the provided context:

        <context>
        {context}
        </context>

        Question: "

llama_base_prompt:
  name: Llama 3 basic prompt
  locales:
    - locale: en
      text: |
        "You are a helpful assistant that avoids causing harm. When you do not know the answer to a question, you say "I don't know\n
        Answer the user's question based on the conversation history: {chat_history} \n\n question: {input}"