<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=../demos/miniloan/ rel=prev><link href=../tutorials/new_mistral_agent/ rel=next><link rel=icon href=../assets/owl.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.44"><title>Gen AI to Hybrid AI - Athena Decision Systems Product Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.0253249f.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#from-generative-ai-to-hybrid-ai class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Athena Decision Systems Product Documentation" class="md-header__button md-logo" aria-label="Athena Decision Systems Product Documentation" data-md-component=logo> <img src=../assets/owl.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Athena Decision Systems Product Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Gen AI to Hybrid AI </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AthenaDecisionSystems/athena-owl-core title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Introduction </a> </li> <li class=md-tabs__item> <a href=../arch/ class=md-tabs__link> Architecture </a> </li> <li class=md-tabs__item> <a href=../demos/ class=md-tabs__link> Demos </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Gen AI to Hybrid AI </a> </li> <li class=md-tabs__item> <a href=../tutorials/new_mistral_agent/ class=md-tabs__link> Tutorials </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Athena Decision Systems Product Documentation" class="md-nav__button md-logo" aria-label="Athena Decision Systems Product Documentation" data-md-component=logo> <img src=../assets/owl.png alt=logo> </a> Athena Decision Systems Product Documentation </label> <div class=md-nav__source> <a href=https://github.com/AthenaDecisionSystems/athena-owl-core title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../arch/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../design/ class=md-nav__link> <span class=md-ellipsis> OwlAgent design </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Demos </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../demos/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../tutorials/dev_env/ class=md-nav__link> <span class=md-ellipsis> Environment Setup </span> </a> </li> <li class=md-nav__item> <a href=../demos/insurance/ class=md-nav__link> <span class=md-ellipsis> IBU Insurance </span> </a> </li> <li class=md-nav__item> <a href=../demos/miniloan/ class=md-nav__link> <span class=md-ellipsis> IBM-ODM LoanApp </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Gen AI to Hybrid AI </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Gen AI to Hybrid AI </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> <nav class=md-nav aria-label=Introduction> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=#challenges class=md-nav__link> <span class=md-ellipsis> Challenges </span> </a> </li> <li class=md-nav__item> <a href=#transformer-architecture class=md-nav__link> <span class=md-ellipsis> Transformer Architecture </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use cases </span> </a> <nav class=md-nav aria-label="Use cases"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#improve-customer-experiences class=md-nav__link> <span class=md-ellipsis> Improve customer experiences </span> </a> </li> <li class=md-nav__item> <a href=#improve-employee-productivity class=md-nav__link> <span class=md-ellipsis> Improve employee productivity </span> </a> </li> <li class=md-nav__item> <a href=#creativity class=md-nav__link> <span class=md-ellipsis> Creativity </span> </a> </li> <li class=md-nav__item> <a href=#business-process-optimization class=md-nav__link> <span class=md-ellipsis> Business process optimization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#retrieval-augmented-generation-rag class=md-nav__link> <span class=md-ellipsis> Retrieval Augmented Generation (RAG) </span> </a> <nav class=md-nav aria-label="Retrieval Augmented Generation (RAG)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-architecture class=md-nav__link> <span class=md-ellipsis> Basic architecture </span> </a> </li> <li class=md-nav__item> <a href=#rag-challenges class=md-nav__link> <span class=md-ellipsis> RAG Challenges </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hybrid-ai class=md-nav__link> <span class=md-ellipsis> Hybrid AI </span> </a> <nav class=md-nav aria-label="Hybrid AI"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-use-hybrid-ai class=md-nav__link> <span class=md-ellipsis> Why Use Hybrid AI? </span> </a> </li> <li class=md-nav__item> <a href=#hybrid-ai-conclusion class=md-nav__link> <span class=md-ellipsis> Hybrid AI Conclusion </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../tutorials/new_mistral_agent/ class=md-nav__link> <span class=md-ellipsis> Building New Mistral Agent </span> </a> </li> <li class=md-nav__item> <a href=../demos/build_sol/ class=md-nav__link> <span class=md-ellipsis> Build Your Own Solution </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> <nav class=md-nav aria-label=Introduction> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=#challenges class=md-nav__link> <span class=md-ellipsis> Challenges </span> </a> </li> <li class=md-nav__item> <a href=#transformer-architecture class=md-nav__link> <span class=md-ellipsis> Transformer Architecture </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use cases </span> </a> <nav class=md-nav aria-label="Use cases"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#improve-customer-experiences class=md-nav__link> <span class=md-ellipsis> Improve customer experiences </span> </a> </li> <li class=md-nav__item> <a href=#improve-employee-productivity class=md-nav__link> <span class=md-ellipsis> Improve employee productivity </span> </a> </li> <li class=md-nav__item> <a href=#creativity class=md-nav__link> <span class=md-ellipsis> Creativity </span> </a> </li> <li class=md-nav__item> <a href=#business-process-optimization class=md-nav__link> <span class=md-ellipsis> Business process optimization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#retrieval-augmented-generation-rag class=md-nav__link> <span class=md-ellipsis> Retrieval Augmented Generation (RAG) </span> </a> <nav class=md-nav aria-label="Retrieval Augmented Generation (RAG)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-architecture class=md-nav__link> <span class=md-ellipsis> Basic architecture </span> </a> </li> <li class=md-nav__item> <a href=#rag-challenges class=md-nav__link> <span class=md-ellipsis> RAG Challenges </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hybrid-ai class=md-nav__link> <span class=md-ellipsis> Hybrid AI </span> </a> <nav class=md-nav aria-label="Hybrid AI"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-use-hybrid-ai class=md-nav__link> <span class=md-ellipsis> Why Use Hybrid AI? </span> </a> </li> <li class=md-nav__item> <a href=#hybrid-ai-conclusion class=md-nav__link> <span class=md-ellipsis> Hybrid AI Conclusion </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <div><h1 id=from-generative-ai-to-hybrid-ai>From Generative AI to Hybrid AI<a class=headerlink href=#from-generative-ai-to-hybrid-ai title="Permanent link">¶</a></h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">¶</a></h2> <p>Generative AI uses special types of neural network models to generate new content (text, images, music, videos, and so on) based on a request that is typically text. Models are pre-trained on vast amounts of unlabeled data, using from 7B to 500B parameters. The models are trained on terabytes of data including books, articles, websites, and whatever else the model trainers can find and feel they can use. This helps the model simulate learning grammar, facts, reasoning abilities and even some level of common sense from the content - because there is a rich store of sequential patterns in the training data to draw on.</p> <p>Gen AI's natural language understanding and generation capabilities applies well to different use cases: improving customer experience through natural language, improving an employee's productivity, provoking creativity by generating ideas based on identifying deep correlations in seemingly unrelated areas, and optimizing certain business processes. Overall, generative AI sometimes seems like magic - and at first it seems like Generative AI is a general intelligence because we humans always associate high level of natural language ability with high intelligence.</p> <h3 id=key-concepts>Key Concepts<a class=headerlink href=#key-concepts title="Permanent link">¶</a></h3> <p>Generative AI today is often used via a chatbot hosted by an AI vendor like OpenAI, Anthropic, IBM, or Mistral. Most of the platforms, including IBM's <code>watsonx.ai</code>, use Large Language Models (LLM) with many query types. The architecture of such a system looks like this:</p> <p><img alt="Chatbot Architecture" src=../diagrams/current_chat_sandbox.drawio.png width=900></p> <p>LLMs are typically hosted on dedicated hardware with GPUs that are needed for high-speed inference. (Inference is the technical term for generating new content with a model.) LLMs are primarily used to do natural language processing (NLP) of unstructured queries from human users. The interactions are stateless, and the concept of a context window is used to include contextual data as part of the query. Contextual data includes previous dialog in a conversation, system prompts, relevant bits of information from other documents (called RAG), or data brought in from databases or external API service calls. As the LLM is essentially stateless, any information used to generate a response must be included in the context, which is why context window size is very important. Since most AI companies charge per token consumed and generated, the more context that is included in each LLM query, the more expensive the query.<sup id=fnref:1><a class=footnote-ref href=#fn:1>1</a></sup></p> <p><img alt="Watsonx.ai screenshot" src=../images/watsonx.ai.main.PNG width=900></p> <p>IBM's watsonx.ai, for example, helps users select which LLM to use, define system prompts, and perform queries. As an enhanced platform, AI scientists can also fine-tune an existing open-source model, or develop brand new ML models.</p> <p>The same approach exists for vendors like Anthropic, OpenAI, Perplexity, Mistral, Hugging Face, Anakin AI, AWS Bedrock, and so on.</p> <p>Models used for inference are accessible via an API.</p> <p>Enterprise deployments of Generative AI need a high degree integration, since enterprise applications need to leverage enterprise-specific instructions, documents, services, and data to perform useful functions for the company. Some tools are already available to help develop Generative AI workflows: For instance watsonx Orchestrate has a no-code approach for leveraging a library of skills. For developers, lower level frameworks, such as LangChain, LlamaIndex, and Haystack offer Python-based libraries with enormous flexibility and a high degree of complexity.</p> <p>A typical real deployment looks like the following figure:</p> <p><img alt="Chatbot with external tools" src=../diagrams/current_itg.drawio.png width=900></p> <p>The backend for a chatbot application needs to be integrated with existing data sources and services including databases, SOA services, Customer Relationship Management platforms, predictive machine learning models and scoring engines, business process management workflows -- and of course business-rule or optimization model based decision services... The data from these services need to be included in a conversation with a human user if it is to be relevant to the user's current context. Fine-tuning the model with the latest information is infeasible when enterprise data changes every second and when decision models can change on a daily basis, so a dynamic approach to getting the data into the LLM's context window is needed. In addition, in order to effect changes in the enterprise environment, the user needs to be able to update data or call services.</p> <p>There are also more and more models that can be hosted for inference on smaller devices with less specialized hardware, which may have significant inference cost and performance improvements vs cloud-hosted models. But hosting these models in an enterprise still requires creating and managing the appropriate environments and handling governance as models evolve as well as secure access to the models.</p> <p>Enterprises have a heterogenous IT environment; solutions need to be deployed on virtual private clouds, on-premises servers, or in an hybrid cloud depending on the enterprise's policies and IT landscape. Other IT considerations such as security and authentication are also paramount.</p> <p>All of this means that when an enterprise wants to deploy an LLM-based solution in production, there will be significant integration and development effort. The OwlAgent Framework attempts to minimize the development effort by providing simple abstractions and a declarative way of combining different components in a specific application.</p> <h3 id=challenges>Challenges<a class=headerlink href=#challenges title="Permanent link">¶</a></h3> <p>LLM's are amazing tools for doing natural language processing. But they come with challenges due to the underlying training and inference technology, due to the fact they are trained only occasionally and are thus the information they use is always out of date, and due to the fact that natural language generation is not grounded in any model of reality or reasoning but instead uses probabilistic techniques based on correlations of a huge number of strings of tokens (words). This means that hallucination and approximate retrieval are core to their architecture: the completions they generate have the same statistical distribution as the text they have been trained on. Prompt engineering cannot eliminate hallucination since the decision to assess the response as a factual completion depends on the knowledge of the prompter and requires continuously assessing all the responses. Various techniques to reduce the impact of this lack of groundedness, such as using multiple LLMs to judge each others' answers, are expensive and only move the problem around.</p> <ul> <li> <p><strong>Accuracy</strong>: The accuracy of LLM's in answering precise questions about enterprise decisions is not acceptable to any enterprise that must follow regulations and policies and respect contractual agreements with suppliers and customers. Because LLMs cannot truly reason or take into account regulations and policies precisely, models often produce incorrect and contradictory answers when asked for decisions or actions to undertake. With classical ML, probabilistic output is expected and scores are combined with thresholds and rules to make final decisions. Symbolic approaches like business rules that precisely express policies produce reliable results at the cost of coding the policies mostly manually.</p> </li> <li> <p><strong>Specificity</strong>: A single large model is unlikely to solve every business problem effectively because it is trained on generally-available information rather than enterprise-specific information. To differentiate their generative AI applications and achieve optimal performance, companies should rely on their <strong>own data sets</strong> tailored to their unique use case. Even then, enterprise data changes constantly, so techniques such as RAG and tool calling are needed to leverage the most up-to-date and relevant information for a specific query.</p> </li> <li> <p><strong>Cost and Risk</strong> of training and inference, as well as privacy and intellectual property are key concerns. LLM's can be "fine-tuned" for a specific task by using a small number of labeled examples specific to the company's industry or use case. Fine-tuned models can deliver more accurate and relevant outputs. But training and retraining models, hosting them, and doing inference with them are expensive. Cloud providers see this opportunity to sell more virtual servers equipped with GPU's at a higher price. In addition, the fine-tuning needs to be redone and retested whenever the information used for it changes, or whenever the underlying model is updated. Therefore, fine-tuning has only limited appeal in practice.</p> </li> <li> <p><strong>Skills</strong>: Developing a new LLM for an enterprise usually makes little sense today, but fine tuning an existing model may in some circumstances. There are relatively few developers with expertise in model tuning, understanding their architecture and limitations, integrating them in applications, and in tuning their hyper parameters. Reinforcement learning to fine-tune existing LLM requires a huge number of trials, and data quality is still a very difficult and poorly-mastered topic.</p> </li> <li> <p><strong>Reliability and reasoning</strong>: Generative AI models do not reason and do not plan accurately and consistently, despite multiple prompting techniques designed to get them to do so. New versions of LLMs attempt to improve this, but by design the transformer algorithm is probabilistic and greedy for text generation and does not inherently do any kind of structured symbolic reasoning or manage ontologies of concepts (knowledge graphs). LLM are very big system-1 with their knowledge based from digital representation of humanity created content. In addition, even if they are able to make simple plans and reason over simple cases, enterprise decisions require very specific, detailed, and complex context and instructions, well beyond the capacity of any LLM reasoning techniques. Imagine, for example, relying on chain-of-thought reasoning to get an LLM to provide expert assistance to an airplane maintenance technician on how to repair a jet engine...</p> </li> </ul> <p>For all of these reasons, we remain firmly convinced that the right way to build AI-based enterprise solutions today is by using a combination of technologies, where generative AI and LLMs play a key role, but other technologies such as symbolic rule-based decision engines are equally key.</p> <p>The next sections explains the generative AI architecture in more detail.</p> <h3 id=transformer-architecture>Transformer Architecture<a class=headerlink href=#transformer-architecture title="Permanent link">¶</a></h3> <p><strong>GPT-3 (Generative Pre-trained Transformer 3)</strong> breaks the NLP boundaries with training on 175B parameters. It is built on <strong>Transformer</strong> which use self-<strong>attention</strong> mechanism to weigh the significance of different words in a sentence to understand the context in a sequence of data.</p> <p>To process a text input with a transformer model, the text is <strong>tokenized</strong> into a sequence of words or part of words. These tokens are then <strong>encoded</strong> as numbers and converted into <strong>embeddings</strong>, which are vector-space representations of the tokens that preserve their meaning. Next, the encoder in the transformer transforms the embeddings of all the tokens into a <strong>context vector</strong>. Using this vector, the transformer decoder generates output based on clues. The decoder can produce the subsequent word. This process can be repeated to create an entire paragraph. This process is called <strong>auto-regressive generation</strong>.</p> <p>The <strong>attention</strong> mechanism computes the similarity between tokens (the embeddings of words) in a sequence. The process keeps few tokens around each word to help understand the context. This surrounding group of tokens is called the <strong>context window</strong>. It is the sliding group of tokens around a word that provides contextual information. That way, the model builds an intuition of what the text is saying. The closer two words are in a vector space, the higher the attention scores they will obtain and the higher the attention they will give to each other.</p> <p>The second part of the GPT-3 architecture is the set of <strong>layers</strong> of transformers stacked on top of each other. Within each layer, there are feed-forward neural networks to process the data.</p> <p>The training has two stages: <strong>Pre-training</strong> where the model attempts to predict the next word in a sentence using its own corpus, and <strong>fine tuning</strong> where the model can be tuned for specific <em>tasks</em> or <em>content</em>. During the pre-training process, the model automatically takes context into account from all the training data, and tracks relationships in sequential data, like the words in a sentence, to develop some understanding of the real world.</p> <p>At <strong>inference</strong> time, the input text is tokenized into individual tokens which are fed into the model. After processing using the transformer mechanism, the model returns result tokens which are then turned back into readable text.</p> <h2 id=use-cases>Use cases<a class=headerlink href=#use-cases title="Permanent link">¶</a></h2> <p>We can group the Generative AI use cases in the following different categories:</p> <h3 id=improve-customer-experiences>Improve customer experiences<a class=headerlink href=#improve-customer-experiences title="Permanent link">¶</a></h3> <ul> <li>Chatbot functionality with context with better user experience than earlier technologies. </li> <li>Reduces operational costs using automated responses.</li> <li>Documentation summarization: See models like Jurassic-2 Jumbo from <a href=https://www.ai21.com/studio>AI21 studio</a>. Anthropic's <code>claude-v2</code> works well too.</li> <li>Personalization</li> </ul> <h3 id=improve-employee-productivity>Improve employee productivity<a class=headerlink href=#improve-employee-productivity title="Permanent link">¶</a></h3> <ul> <li>Code generation</li> <li>Translation, reports, summarization...</li> <li> <p>Search via Q&amp;A Agent for specific subjects, based on enterprise document processing. The LLM helps understanding the text and the questions. The LLM is enriched and trained on a proprietary corpus:</p> <p><img alt="RAG chatbot" src=../diagrams/qa_llm.drawio.png width=600></p> </li> <li> <p>Self service tutor based on student progress, prompt activities, and respond to questions</p> </li> <li>Personalized learning path generation</li> <li>Low-code development with GenAI agents</li> </ul> <h3 id=creativity>Creativity<a class=headerlink href=#creativity title="Permanent link">¶</a></h3> <ul> <li>Auto-generation of marketing material</li> <li>Personalized emails</li> <li>Sales scripts for customer's industry or segment</li> <li>Speeding the ideation phase of a product development</li> </ul> <h3 id=business-process-optimization>Business process optimization<a class=headerlink href=#business-process-optimization title="Permanent link">¶</a></h3> <ul> <li> <p>Automatically extract and summarize data from documents: combine OCR with prompt to extract data and build json doc to be structured for downstream processing: Gen AI based intelligent document processing may look like this:</p> <p><img alt="Document Processing Flow" src=../diagrams/idp_genai.drawio.png width=600></p> </li> <li> <p>Data augmentation to improve data set quality. Keep the privacy of original data sources, and help trains other models: generate image of rusted pumps to train an anomaly detection model on pumps.</p> </li> <li>Propose some supply chain scenario</li> </ul> <h2 id=retrieval-augmented-generation-rag>Retrieval Augmented Generation (RAG)<a class=headerlink href=#retrieval-augmented-generation-rag title="Permanent link">¶</a></h2> <p>LLMs are trained at a specific moment in time, and therefore have a knowledge cut-off time, after which data are not directly available to the model. When enterprises need their LLM-based applications to use private information, they can fine-tune models or insert semantic search results into the LLM's input context window. Retrieval Augmented Generation is an approach that addresses this problem by supplementing generative text models with data that it was not trained on but is discovered by examining the user's query and finding relevant additional information prior to calling the LLM.</p> <h3 id=basic-architecture>Basic architecture<a class=headerlink href=#basic-architecture title="Permanent link">¶</a></h3> <p>The Retrieval Augmented Generation may be seen as a three stage process:</p> <p><img alt="RAG Stages" src=../diagrams/rag_3_stages.drawio.png width=900></p> <ol> <li><strong>Indexing</strong>: A batch process to ingest documents and data from a source and index them. During this process semantic search is used to retrieve relevant documents from the index. Indexing supports reading the documents and splitting large ones into smaller chunks. Chunks help to stay within the LLM's context window. Indexing includes storage of the documents and index the chunks.</li> <li><strong>Retrieval</strong>: Retrieves the relevant data (chunks) from the index, then pass that to the model as part of the context.</li> <li><strong>Generation</strong>: Generate the response in plain natural language.</li> </ol> <p>This process is supported by tools for documents ingestion, splitting, embedding, indexing, retrieval and integration with the real time conversation flow.</p> <p>RAG systems work well because LLMs has the in-context learning capability, which allows models to use previously unseen data to perform accurate predictions without weight training.</p> <p>As LLM increase the context window size over new release, RAG can add more new data to it.</p> <h3 id=rag-challenges>RAG Challenges<a class=headerlink href=#rag-challenges title="Permanent link">¶</a></h3> <p>Naive RAG has severe limitations which has limited large-scale adoption:</p> <ul> <li>It is hard to do reliable, scalable RAG on a large knowledge corpus.</li> <li>Limited to single-shot prompts.</li> <li>No query understanding, just a sematic search.</li> <li>No query decomposition for planning.</li> <li>No tool use to query an external data source to enrich the context.</li> <li>No reflection and error correction to improve the quality of the response.</li> <li>No persistence or memory of previous queries.</li> </ul> <p>Therefore, while invaluable for enriching context, RAG often needs to be enhanced with other technologies and approaches for full-scale enterprise applications.</p> <h2 id=hybrid-ai>Hybrid AI<a class=headerlink href=#hybrid-ai title="Permanent link">¶</a></h2> <p>Hybrid AI refers to the integration of different AI approaches or techniques to create more robust and capable AI systems. The classical hybrid AI is to combine traditional, rule-based <strong>symbolic AI</strong> systems with deep learning models. The rule-based engine can handle logical reasoning and knowledge representation, while the deep learning component handles pattern recognition and unstructured data processing.</p> <p>In addition to rule-based systems, Hybrid AI solutions can also leverage other decision engines such as optimization engines, knowledge graphs, or synbolic planning engines for specialized domain-specific applications. In addition, all of these can be enhanced with specialized machine learning models to provide additional contextual information about historical patterns and scores.</p> <p>Another architecture for hybrid AI a multi-agent system, which combines multiple specialized AI agents, each with their own capabilities and decision-making processes, to tackle complex problems that require diverse skills and perspectives. These agents can be chained together or deployed for parallel processing. Agents are stateful.</p> <p>Here is a typical example of a hybrid AI architecture:</p> <p><img alt="Hybrid AI Architecture" src=../diagrams/hybrid_ai_comp.drawio.png width=900></p> <p>The backend for a chatbot includes assistants that organize an agent workflow, that integrates LLMs, classical machine learning predictive scoring models, knowledge graphs, rule-based engines, and vector stores for similarity searches. Such an agent workflow is stateful.</p> <h3 id=why-use-hybrid-ai>Why Use Hybrid AI?<a class=headerlink href=#why-use-hybrid-ai title="Permanent link">¶</a></h3> <p>Hybrid systems can achieve better overall accuracy than a generic LLM; they are more resilient to the weaknesses or limitations of LLMs. They are grounded, precise, transparent, and more amenable to meaningful explanations of their behavior and decisions. They can take into account up-to-date data from documents and data within the enterprise. The use of knowledge graph and rule-based systems make the AI architecture more flexible to support a wider range of problems and scenarios.</p> <p>When an enterprise must demonstrate compliance and follow specific policies and regulations, symbolic AI results are more interpretable and explainable than neural network decisions. This is critical both for good organizational behavior and for audits.</p> <h3 id=hybrid-ai-conclusion>Hybrid AI Conclusion<a class=headerlink href=#hybrid-ai-conclusion title="Permanent link">¶</a></h3> <p>Of course, leveraging multiple technologies comes at a cost: The architecture, development, and governance costs of maintaining such a solution is significant. Typically symbolic engine solutions must be hand-coded (for example, business rules must be discovered, authored, tested, and deployed). Machine learning models must be trained on large amounts of data. RAG systems depend on a curated and processed corpus of documents.</p> <p>All of this is real work that requires people with skills and experience. Tools exist and are being enhanced all the time to simplify the process of creating and maintaining these components, but enterprises should go into these projects with their eyes open to avoid frustration and disappointment. AI can produce great results - but it's not magic. Our recommendation: work with people experienced not only the latest AI technologies, but in created real, deployed, enterprise systems, and people who have experience with the full breadth of tools that can be brought to bear to create a meaningful solution for your business.</p> <div class=footnote> <hr> <ol> <li id=fn:1> <p>We use the term <em>query</em>, but in reality the LLM generates the next most likely tokens after the content of the context window given its training model; no database or other external data source is queried per se. Any such external reference is done by adding more data to the context window; techniques like <em>tool calling</em> iteratively add information to the context by calling 3<sup>rd</sup> party APIs. <a class=footnote-backref href=#fnref:1 title="Jump back to footnote 1 in the text">↩</a></p> </li> </ol> </div></div> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../demos/miniloan/ class="md-footer__link md-footer__link--prev" aria-label="Previous: IBM-ODM LoanApp"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> IBM-ODM LoanApp </div> </div> </a> <a href=../tutorials/new_mistral_agent/ class="md-footer__link md-footer__link--next" aria-label="Next: Building New Mistral Agent"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Building New Mistral Agent </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Athena Decision Systems </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/AthenaDecisionSystems target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://www.linkedin.com/company/athena-decision-systems/ target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.tracking", "navigation.top", "navigation.footer"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.83f73b43.min.js></script> </body> </html>